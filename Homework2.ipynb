{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework2\n",
    "\n",
    "### Mandatory Task:\n",
    "You are to solve the first sub-problem: to implement the A-Priori algorithm for finding frequent itemsets with support at least s in a dataset of sales transactions. Remind that support of an itemset is the number of transactions containing the itemset. To test and evaluate your implementation, write a program that uses your A-Priori algorithm implementation to discover frequent itemsets with support at least s in a given dataset of sales transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "import findspark\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/11/12 18:35:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# initializing Spark\n",
    "findspark.init()\n",
    "conf = SparkConf().setAppName(\"FreqItemSets\").setMaster(\"local[*]\")\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['25', '52', '164', '240', '274', '328', '368', '448', '538', '561', '630', '687', '730', '775', '825', '834']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "transactions = sc.textFile(\"datasets/transaction_dataset.txt\").map(lambda line: line.strip().split(\" \"))\n",
    "print(transactions.first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "333.036\n"
     ]
    }
   ],
   "source": [
    "# Parameters:\n",
    "s = 0.022 # support threshold - 0.018 there is 3-itemsets as well, but running time is too much for me\n",
    "num_of_transactions = transactions.count()\n",
    "frequency_threshold = s * num_of_transactions # how many times should the itemset apper to be frequent\n",
    "print(frequency_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_candidates(prev_freq_itemsets, freq_1_itemsets, k):\n",
    "    \"\"\"Generate candidate k-itemsets by pairing (k-1)-itemsets with 1-itemsets.\"\"\"\n",
    "    candidates = set()\n",
    "    \n",
    "    for itemset in prev_freq_itemsets:\n",
    "        for item in freq_1_itemsets:\n",
    "            # Create a new candidate by adding the 1-itemset to the (k-1)-itemset\n",
    "            candidate = itemset | frozenset([item])\n",
    "            \n",
    "            # Only add if the resulting candidate has exactly k items\n",
    "            if len(candidate) == k:\n",
    "                candidates.add(candidate)\n",
    "    \n",
    "    return candidates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_candidates(candidates, prev_freq_itemsets):\n",
    "    \"\"\"Prune candidate k-itemsets by removing those with infrequent (k-1)-itemset subsets.\"\"\"\n",
    "    pruned_candidates = set()\n",
    "    \n",
    "    for candidate in candidates:\n",
    "        is_valid = True\n",
    "        # Generate all possible (k-1)-itemsets by removing one item at a time\n",
    "        for item in candidate:\n",
    "            subset = candidate - frozenset([item])\n",
    "            # Check if the subset is in the frequent (k-1)-itemsets\n",
    "            if subset not in prev_freq_itemsets:\n",
    "                is_valid = False\n",
    "                break\n",
    "        # If all (k-1)-subsets are frequent, add candidate to the pruned set\n",
    "        if is_valid:\n",
    "            pruned_candidates.add(candidate)\n",
    "    \n",
    "    return pruned_candidates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                                                          (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "freq_itemsets = dict()\n",
    "\n",
    "item_appear = transactions.flatMap(lambda items: [(item, 1) for item in items]).reduceByKey(lambda x, y: x+y)\n",
    "freq_1_itemsets = item_appear.filter(lambda item: item[1] >= frequency_threshold).map(lambda item: item[0]).collect()\n",
    "print(len(freq_1_itemsets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_1_itemsets = set(freq_1_itemsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_k_itemsets = set(frozenset([item]) for item in freq_1_itemsets)\n",
    "freq_itemsets[1] = freq_k_itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:=======================================>                   (4 + 2) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent 2-itemsets: {frozenset({'39', '825'}), frozenset({'789', '829'}), frozenset({'346', '217'}), frozenset({'829', '368'}), frozenset({'368', '682'})}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "k=2\n",
    "\n",
    "while True:\n",
    "    candidates_k = generate_candidates(freq_itemsets[k-1], freq_1_itemsets, k)\n",
    "    if not candidates_k:\n",
    "        break\n",
    "    \n",
    "    #Pruning:\n",
    "    candidates_k = prune_candidates(candidates_k, freq_itemsets[k-1])\n",
    "    if not candidates_k:\n",
    "        break\n",
    "    \n",
    "    candidates_k_rdd = sc.parallelize(list(candidates_k)).map(lambda item: (item, 1))\n",
    "    \n",
    "    transaction_k_itemsets = transactions.flatMap(lambda transaction: [frozenset(combo) for combo in combinations(transaction, k)]).map(lambda x: (x, 1))\n",
    "        \n",
    "    # Join candidate itemsets with transaction itemsets to count support\n",
    "    candidate_counts = candidates_k_rdd.join(transaction_k_itemsets).map(lambda x: (x[0], x[1][0] + x[1][1])).reduceByKey(lambda a, b: a + b)\n",
    "    \n",
    "    freq_k_itemsets = candidate_counts.filter(lambda x: x[1] >= frequency_threshold).map(lambda x: x[0]).collect()\n",
    "        \n",
    "    freq_k_itemsets = set(freq_k_itemsets)\n",
    "    if not freq_k_itemsets:\n",
    "        break\n",
    "\n",
    "    freq_itemsets[k] = freq_k_itemsets\n",
    "    print(f\"Frequent {k}-itemsets: {freq_itemsets[k]}\")\n",
    "    k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_frequent_itemsets = []\n",
    "for size, itemsets in freq_itemsets.items():\n",
    "    for itemset in itemsets:\n",
    "        all_frequent_itemsets.append((itemset, size))\n",
    "\n",
    "all_frequent_itemsets = sorted(all_frequent_itemsets, key=lambda x: (x[1], sorted(x[0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All Frequent Itemsets:\n",
      "Itemset: {'112'}, Size: 1\n",
      "Itemset: {'12'}, Size: 1\n",
      "Itemset: {'120'}, Size: 1\n",
      "Itemset: {'132'}, Size: 1\n",
      "Itemset: {'140'}, Size: 1\n",
      "Itemset: {'145'}, Size: 1\n",
      "Itemset: {'151'}, Size: 1\n",
      "Itemset: {'161'}, Size: 1\n",
      "Itemset: {'175'}, Size: 1\n",
      "Itemset: {'177'}, Size: 1\n",
      "Itemset: {'183'}, Size: 1\n",
      "Itemset: {'204'}, Size: 1\n",
      "Itemset: {'205'}, Size: 1\n",
      "Itemset: {'21'}, Size: 1\n",
      "Itemset: {'217'}, Size: 1\n",
      "Itemset: {'236'}, Size: 1\n",
      "Itemset: {'239'}, Size: 1\n",
      "Itemset: {'242'}, Size: 1\n",
      "Itemset: {'27'}, Size: 1\n",
      "Itemset: {'274'}, Size: 1\n",
      "Itemset: {'276'}, Size: 1\n",
      "Itemset: {'279'}, Size: 1\n",
      "Itemset: {'283'}, Size: 1\n",
      "Itemset: {'285'}, Size: 1\n",
      "Itemset: {'296'}, Size: 1\n",
      "Itemset: {'32'}, Size: 1\n",
      "Itemset: {'346'}, Size: 1\n",
      "Itemset: {'350'}, Size: 1\n",
      "Itemset: {'354'}, Size: 1\n",
      "Itemset: {'362'}, Size: 1\n",
      "Itemset: {'368'}, Size: 1\n",
      "Itemset: {'38'}, Size: 1\n",
      "Itemset: {'381'}, Size: 1\n",
      "Itemset: {'39'}, Size: 1\n",
      "Itemset: {'390'}, Size: 1\n",
      "Itemset: {'392'}, Size: 1\n",
      "Itemset: {'401'}, Size: 1\n",
      "Itemset: {'413'}, Size: 1\n",
      "Itemset: {'419'}, Size: 1\n",
      "Itemset: {'438'}, Size: 1\n",
      "Itemset: {'460'}, Size: 1\n",
      "Itemset: {'470'}, Size: 1\n",
      "Itemset: {'471'}, Size: 1\n",
      "Itemset: {'477'}, Size: 1\n",
      "Itemset: {'48'}, Size: 1\n",
      "Itemset: {'480'}, Size: 1\n",
      "Itemset: {'487'}, Size: 1\n",
      "Itemset: {'489'}, Size: 1\n",
      "Itemset: {'494'}, Size: 1\n",
      "Itemset: {'509'}, Size: 1\n",
      "Itemset: {'510'}, Size: 1\n",
      "Itemset: {'522'}, Size: 1\n",
      "Itemset: {'523'}, Size: 1\n",
      "Itemset: {'526'}, Size: 1\n",
      "Itemset: {'529'}, Size: 1\n",
      "Itemset: {'538'}, Size: 1\n",
      "Itemset: {'54'}, Size: 1\n",
      "Itemset: {'541'}, Size: 1\n",
      "Itemset: {'548'}, Size: 1\n",
      "Itemset: {'561'}, Size: 1\n",
      "Itemset: {'569'}, Size: 1\n",
      "Itemset: {'57'}, Size: 1\n",
      "Itemset: {'571'}, Size: 1\n",
      "Itemset: {'579'}, Size: 1\n",
      "Itemset: {'581'}, Size: 1\n",
      "Itemset: {'593'}, Size: 1\n",
      "Itemset: {'597'}, Size: 1\n",
      "Itemset: {'598'}, Size: 1\n",
      "Itemset: {'606'}, Size: 1\n",
      "Itemset: {'614'}, Size: 1\n",
      "Itemset: {'617'}, Size: 1\n",
      "Itemset: {'620'}, Size: 1\n",
      "Itemset: {'631'}, Size: 1\n",
      "Itemset: {'634'}, Size: 1\n",
      "Itemset: {'653'}, Size: 1\n",
      "Itemset: {'661'}, Size: 1\n",
      "Itemset: {'674'}, Size: 1\n",
      "Itemset: {'675'}, Size: 1\n",
      "Itemset: {'676'}, Size: 1\n",
      "Itemset: {'682'}, Size: 1\n",
      "Itemset: {'684'}, Size: 1\n",
      "Itemset: {'69'}, Size: 1\n",
      "Itemset: {'692'}, Size: 1\n",
      "Itemset: {'694'}, Size: 1\n",
      "Itemset: {'70'}, Size: 1\n",
      "Itemset: {'71'}, Size: 1\n",
      "Itemset: {'72'}, Size: 1\n",
      "Itemset: {'720'}, Size: 1\n",
      "Itemset: {'722'}, Size: 1\n",
      "Itemset: {'75'}, Size: 1\n",
      "Itemset: {'752'}, Size: 1\n",
      "Itemset: {'758'}, Size: 1\n",
      "Itemset: {'766'}, Size: 1\n",
      "Itemset: {'775'}, Size: 1\n",
      "Itemset: {'778'}, Size: 1\n",
      "Itemset: {'78'}, Size: 1\n",
      "Itemset: {'780'}, Size: 1\n",
      "Itemset: {'782'}, Size: 1\n",
      "Itemset: {'788'}, Size: 1\n",
      "Itemset: {'789'}, Size: 1\n",
      "Itemset: {'793'}, Size: 1\n",
      "Itemset: {'795'}, Size: 1\n",
      "Itemset: {'797'}, Size: 1\n",
      "Itemset: {'798'}, Size: 1\n",
      "Itemset: {'8'}, Size: 1\n",
      "Itemset: {'803'}, Size: 1\n",
      "Itemset: {'825'}, Size: 1\n",
      "Itemset: {'829'}, Size: 1\n",
      "Itemset: {'844'}, Size: 1\n",
      "Itemset: {'854'}, Size: 1\n",
      "Itemset: {'862'}, Size: 1\n",
      "Itemset: {'871'}, Size: 1\n",
      "Itemset: {'874'}, Size: 1\n",
      "Itemset: {'883'}, Size: 1\n",
      "Itemset: {'885'}, Size: 1\n",
      "Itemset: {'886'}, Size: 1\n",
      "Itemset: {'888'}, Size: 1\n",
      "Itemset: {'895'}, Size: 1\n",
      "Itemset: {'914'}, Size: 1\n",
      "Itemset: {'918'}, Size: 1\n",
      "Itemset: {'919'}, Size: 1\n",
      "Itemset: {'921'}, Size: 1\n",
      "Itemset: {'93'}, Size: 1\n",
      "Itemset: {'937'}, Size: 1\n",
      "Itemset: {'944'}, Size: 1\n",
      "Itemset: {'947'}, Size: 1\n",
      "Itemset: {'956'}, Size: 1\n",
      "Itemset: {'960'}, Size: 1\n",
      "Itemset: {'966'}, Size: 1\n",
      "Itemset: {'998'}, Size: 1\n",
      "Itemset: {'346', '217'}, Size: 2\n",
      "Itemset: {'368', '682'}, Size: 2\n",
      "Itemset: {'829', '368'}, Size: 2\n",
      "Itemset: {'39', '825'}, Size: 2\n",
      "Itemset: {'789', '829'}, Size: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nAll Frequent Itemsets:\")\n",
    "for itemset, size in all_frequent_itemsets:\n",
    "    print(f\"Itemset: {set(itemset)}, Size: {size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
